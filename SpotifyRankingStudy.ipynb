{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![AltText](http://www.scdn.co/i/_global/open-graph-default.png \"Spotify Logo\")\n",
    "\n",
    "\n",
    "# Introduction and Motivations\n",
    "\n",
    "\n",
    "## Proposal\n",
    "\n",
    "To introduce the subject material and understand the motivations behind this study, we first recall our original project proposal:\n",
    ">As people who are like music and have received some form of musical training, we decided to do our data science topic on songs.  A look at the Spotify data obtained in Kaggle has shown lists of top ranking songs, some song classifications, and some attributes that are known as \"audio analyses.\"  Metrics such as \"danceability\" and \"energy\" are given quantitative values and are available through Spotify's API.  We intend to use this data as a data lake for our experiments in order to find out what Spotify looks for in a hit.  \n",
    "\n",
    ">We'd like to answer questions such as \"Given today's trends, what does it take to make it to Spotify's top 50 songs?\"  and \"What's more important for streaming numbers today, instrumentalness or danceability?\"  We add the qualifier for the present because at the moment we do not have access to such ranking data from 2016 or earlier.\n",
    "\n",
    "## Defining the Question\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "As outlined in the proposal, we'd like to find out what makes up a Spotify hit.  Which of the audio features are the most important?  What gets more listens - vocals-based music like rap or instrumentals like EDM?  The potential significance of such questions are at least two-fold: \n",
    "\n",
    "1. To dvelop some sort of model that could determine if a song's characteristics are enough to be a Spotify chart-topper\n",
    "2. If enough data can be collected, to perhaps even correlate song popularity with production techniques. For example Max Martin is a producer who's considered to have a \"magic touch\" - he has produced or co-written 22 Billboard Hot 100 **CHART TOPPERS**.  It would be interesting to find out what are his secrets to success.\n",
    "\n",
    "More info on Max Martin from infowetrust.com: \n",
    "\n",
    "![AltText](https://i1.wp.com/infowetrust.com/wp-content/uploads/2015/11/Who-is-Max-Martin-03.png?w=2100 \"Who is Max Martin?\")  ![AltText](https://www.independent.ie/opinion/article31413539.ece/ALTERNATES/h342/2015-08-01_opi_11500704_I2.JPG \"What's he hiding?\")\n",
    "\n",
    "\n",
    "\n",
    "# Methods and Tools\n",
    "\n",
    "## Getting the Data\n",
    "\n",
    "![AltText](https://kaggle2.blob.core.windows.net/competitions/kaggle/3136/media/kaggle-transparent.svg \"Kaggle Logo\")\n",
    "\n",
    "For the unfamiliar, Spotify is a digital music, podcast, and video streaming service that provides access to more than 30 million songs.  Spotify's Charts rank songs by the number of streams - we obtained the top 100 songs of 2017 to conduct our analysis.  The dataset is available here: https://www.kaggle.com/nadintamer/top-tracks-of-2017/downloads/featuresdf.csv/1 \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Analysis and Visualization\n",
    "We will use the IPython environment to conduct our analysis, and our results will be reported in this notebook.  We start by setting up our notebook with the Pandas, Seaborn,and matplotlib libraries.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sklearn as skl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then read our csv data into a dataframe.  The dataset contains other information beyond the name of the songs and its ranking, as shown below.  We also check that the dataset is complete and void of duplicates.  Fortunately, our starting data is clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>artists</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>time_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7qiZfU4dY1lWllzX7mPBI</td>\n",
       "      <td>Shape of You</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.652</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.183</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0802</td>\n",
       "      <td>0.581000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0931</td>\n",
       "      <td>0.931</td>\n",
       "      <td>95.977</td>\n",
       "      <td>233713.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5CtI0qwDJkDQGwXD1H1cL</td>\n",
       "      <td>Despacito - Remix</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.815</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-4.328</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>0.229000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0924</td>\n",
       "      <td>0.813</td>\n",
       "      <td>88.931</td>\n",
       "      <td>228827.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4aWmUDTfIPGksMNLV2rQP</td>\n",
       "      <td>Despacito (Featuring Daddy Yankee)</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.786</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-4.757</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1700</td>\n",
       "      <td>0.209000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1120</td>\n",
       "      <td>0.846</td>\n",
       "      <td>177.833</td>\n",
       "      <td>228200.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6RUKPb4LETWmmr3iAEQkt</td>\n",
       "      <td>Something Just Like This</td>\n",
       "      <td>The Chainsmokers</td>\n",
       "      <td>0.617</td>\n",
       "      <td>0.635</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-6.769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0317</td>\n",
       "      <td>0.049800</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.1640</td>\n",
       "      <td>0.446</td>\n",
       "      <td>103.019</td>\n",
       "      <td>247160.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3DXncPQOG4VBw3QHh3S81</td>\n",
       "      <td>I'm the One</td>\n",
       "      <td>DJ Khaled</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.668</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-4.284</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0367</td>\n",
       "      <td>0.055200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1670</td>\n",
       "      <td>0.811</td>\n",
       "      <td>80.924</td>\n",
       "      <td>288600.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7KXjTSCq5nL1LoYtL7XAw</td>\n",
       "      <td>HUMBLE.</td>\n",
       "      <td>Kendrick Lamar</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.611</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0888</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.0976</td>\n",
       "      <td>0.400</td>\n",
       "      <td>150.020</td>\n",
       "      <td>177000.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3eR23VReFzcdmS7TYCrhC</td>\n",
       "      <td>It Ain't Me (with Selena Gomez)</td>\n",
       "      <td>Kygo</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.596</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0706</td>\n",
       "      <td>0.119000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0864</td>\n",
       "      <td>0.515</td>\n",
       "      <td>99.968</td>\n",
       "      <td>220781.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3B54sVLJ402zGa6Xm4YGN</td>\n",
       "      <td>Unforgettable</td>\n",
       "      <td>French Montana</td>\n",
       "      <td>0.726</td>\n",
       "      <td>0.769</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-5.043</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1230</td>\n",
       "      <td>0.029300</td>\n",
       "      <td>0.010100</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>0.733</td>\n",
       "      <td>97.985</td>\n",
       "      <td>233902.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                name  \\\n",
       "0  7qiZfU4dY1lWllzX7mPBI                        Shape of You   \n",
       "1  5CtI0qwDJkDQGwXD1H1cL                   Despacito - Remix   \n",
       "2  4aWmUDTfIPGksMNLV2rQP  Despacito (Featuring Daddy Yankee)   \n",
       "3  6RUKPb4LETWmmr3iAEQkt            Something Just Like This   \n",
       "4  3DXncPQOG4VBw3QHh3S81                         I'm the One   \n",
       "5  7KXjTSCq5nL1LoYtL7XAw                             HUMBLE.   \n",
       "6  3eR23VReFzcdmS7TYCrhC     It Ain't Me (with Selena Gomez)   \n",
       "7  3B54sVLJ402zGa6Xm4YGN                       Unforgettable   \n",
       "\n",
       "            artists  danceability  energy   key  loudness  mode  speechiness  \\\n",
       "0        Ed Sheeran         0.825   0.652   1.0    -3.183   0.0       0.0802   \n",
       "1        Luis Fonsi         0.694   0.815   2.0    -4.328   1.0       0.1200   \n",
       "2        Luis Fonsi         0.660   0.786   2.0    -4.757   1.0       0.1700   \n",
       "3  The Chainsmokers         0.617   0.635  11.0    -6.769   0.0       0.0317   \n",
       "4         DJ Khaled         0.609   0.668   7.0    -4.284   1.0       0.0367   \n",
       "5    Kendrick Lamar         0.904   0.611   1.0    -6.842   0.0       0.0888   \n",
       "6              Kygo         0.640   0.533   0.0    -6.596   1.0       0.0706   \n",
       "7    French Montana         0.726   0.769   6.0    -5.043   1.0       0.1230   \n",
       "\n",
       "   acousticness  instrumentalness  liveness  valence    tempo  duration_ms  \\\n",
       "0      0.581000          0.000000    0.0931    0.931   95.977     233713.0   \n",
       "1      0.229000          0.000000    0.0924    0.813   88.931     228827.0   \n",
       "2      0.209000          0.000000    0.1120    0.846  177.833     228200.0   \n",
       "3      0.049800          0.000014    0.1640    0.446  103.019     247160.0   \n",
       "4      0.055200          0.000000    0.1670    0.811   80.924     288600.0   \n",
       "5      0.000259          0.000020    0.0976    0.400  150.020     177000.0   \n",
       "6      0.119000          0.000000    0.0864    0.515   99.968     220781.0   \n",
       "7      0.029300          0.010100    0.1040    0.733   97.985     233902.0   \n",
       "\n",
       "   time_signature  \n",
       "0             4.0  \n",
       "1             4.0  \n",
       "2             4.0  \n",
       "3             4.0  \n",
       "4             4.0  \n",
       "5             4.0  \n",
       "6             4.0  \n",
       "7             4.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sdata = pd.read_csv('./featuresdf.csv')\n",
    "sdata = pd.read_csv('./smaller.csv')\n",
    "sdata.head(8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2500 entries, 0 to 2499\n",
      "Data columns (total 16 columns):\n",
      "id                  2500 non-null object\n",
      "name                2500 non-null object\n",
      "artists             2500 non-null object\n",
      "danceability        2500 non-null float64\n",
      "energy              2500 non-null float64\n",
      "key                 2500 non-null float64\n",
      "loudness            2500 non-null float64\n",
      "mode                2500 non-null float64\n",
      "speechiness         2500 non-null float64\n",
      "acousticness        2500 non-null float64\n",
      "instrumentalness    2500 non-null float64\n",
      "liveness            2500 non-null float64\n",
      "valence             2500 non-null float64\n",
      "tempo               2500 non-null float64\n",
      "duration_ms         2500 non-null float64\n",
      "time_signature      2500 non-null float64\n",
      "dtypes: float64(13), object(3)\n",
      "memory usage: 312.6+ KB\n"
     ]
    }
   ],
   "source": [
    "sdata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2400"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for duplicates\n",
    "len(sdata[sdata.duplicated() == True])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data Fields\n",
    "We now examine the fields within the data set.  The first 3 fields are arranged as follows:\n",
    "+ **id**: \n",
    "    + Spotify URI\n",
    "+ **name**: \n",
    "    + title\n",
    "+ **artists**: \n",
    "    + contributing artists\n",
    "\n",
    "\n",
    "The following fields are song attributes or audio features that are provided by Spotify via the Spotify API (descriptions taken from https://beta.developer.spotify.com/documentation/web-api/reference/tracks/get-several-audio-features/):\n",
    "+ **danceability**: \n",
    "    + describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity. \n",
    "    + value of 0.0 is least danceable and 1.0 is most danceable.\n",
    "+ **energy**: \n",
    "    + measure from 0.0 to 1.0 which represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale. \n",
    "    + perceptual features contributing to this attribute include dynamic range, perceived loudness, timbre, onset rate, and general entropy.\n",
    "+ **key**: \n",
    "   + the key the track is in. \n",
    "   + integers map to pitches using standard Pitch Class notation. E.g. 0 = C, 1 = C♯/D♭, 2 = D, and so on.\n",
    "+ **loudness**:  \n",
    "   + overall loudness of a track in decibels (dB). Loudness values are averaged across the entire track and are useful for comparing relative loudness of tracks. \n",
    "   + values typical range between -60 and 0 db.\n",
    "+ **mode**: \n",
    "    + indicates the modality (major or minor) of a track, the type of scale from which its melodic content is derived. \n",
    "    + major is represented by 1 and minor is 0.\n",
    "+ **speechiness**:  \n",
    "    + detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0 the attribute value. \n",
    "    + values above 0.66 describe tracks that are probably made entirely of spoken words. \n",
    "    + values between 0.33 and 0.66 describe tracks that may contain both music and speech. \n",
    "    + values below 0.33 most likely represent music and other non-speech-like tracks.\n",
    "+ **acousticness**: \n",
    "    + confidence measure from 0.0 to 1.0 of whether the track is acoustic. \n",
    "    + 1.0 represents high confidence the track is acoustic.\n",
    "+ **instrumentalness**: \n",
    "    + predicts whether a track contains no vocals. “Ooh” and “aah” sounds are treated as instrumental in this context. \n",
    "    + values above 0.5 are intended to represent instrumental tracks, but confidence is higher as the value approaches 1.0.\n",
    "+ **liveness**: \n",
    "    + detects the presence of an audience in the recording. \n",
    "    + value above 0.8 provides strong likelihood that the track is live.\n",
    "+ **valence**: \n",
    "    + measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).\n",
    "+ **tempo**:  \n",
    "    + overall estimated tempo of a track in beats per minute (BPM). \n",
    "    + derives directly from the average beat duration.\n",
    "+ **duration_ms**: \n",
    "    + duration of the track in milliseconds.\n",
    "+ **time_signature**: \n",
    "    + estimated overall time signature of a track. The time signature (meter) is a notational convention to specify how many beats are in each bar (or measure)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary Analysis\n",
    "\n",
    "To get a general feel of what the data distribution is for our dataset, we first plot each column as a histogram. \n",
    "\n",
    "## Histograms\n",
    "\n",
    "To construct the histograms, we first divide the range of values into \"bins,\" or intervals.  The bin size is first determined using Sturge's rule: \n",
    "\n",
    "$$k = 1 + 3.322 * \\log_10{n}$$\n",
    "\n",
    "where k is the number of classes and n is the number of total observations (which is 100 in this case).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Distplot each of the song attributes\n",
    "\n",
    "fig1_1 = plt.figure(figsize = (20, 56))\n",
    "\n",
    "pal = sns.color_palette(\"bright\", 13)\n",
    "\n",
    "for num in range(1, 14):\n",
    "    plt.subplot(14, 2, num)\n",
    "    a = sns.distplot(sdata[list(sdata)[num + 2]], bins= 35, color = pal[num -1], rug = True, kde = False)\n",
    "    a.set_xlabel(list(sdata)[num+2], fontsize = 15)\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "First thoughts on examining the data representation:\n",
    "+ Popular songs have a 4/4 time signature\n",
    "+ Popular songs have vocals\n",
    "+ There is a rough 40/60 split between the tracks that use a minor key and the tracks that use a major key - one does category does not dominate the other\n",
    "We realize that  it is better to know the modality and the key of a track together as a distinct data point.  Hence, we introduce a new category of **keyscore** through a simple formula: \n",
    "\n",
    "$$keyscore = key + 0.5*mode$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1_2 = plt.figure(figsize = (10, 6))\n",
    "\n",
    "\n",
    "sdata['keyscore'] = sdata['key'] + 0.5 * sdata['mode']\n",
    "a = fig1_2.add_subplot(1,1,1)\n",
    "a.set_xlabel('keyscore', fontsize = 15)\n",
    "\n",
    "a = sns.distplot(sdata['keyscore'], bins=22, #22 keys + mode pairs\n",
    "                 color = pal[3], rug = True, kde = False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining Correlations\n",
    "\n",
    "\n",
    "From the knowledge gained above, we render time_signature, instrumentalness, key, and mode as relatively irrelevant variables.  With the addition of the keyscore metric, there are now 10 different dimensions to examine, with only 100 data points.  It is beneficial to reduce data dimensionality in order to restrict analysis to the most relevant features.  We use a heatmap to investigate how strongly data columns correlate with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant = [\"danceability\", \"energy\", \"keyscore\", \"loudness\", \"speechiness\", \"acousticness\", \"liveness\", \"valence\", \"tempo\", \"duration_ms\"]\n",
    "\n",
    "heatmapdf = sdata[relevant].copy()\n",
    "\n",
    "correlation = heatmapdf.corr()\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.title('Column Correlation Heatmap')\n",
    "\n",
    "sns.heatmap(correlation, vmax=1, square=True,annot=True,cmap='cubehelix')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA \n",
    "The components do not demonstrate a lot of correlation.  Most of the variables are in fact negatively correlated, but there are four pairwise comparisons of note:\n",
    "    1. loudness and energy\n",
    "    2. valence and danceability\n",
    "    3. valence and energy\n",
    "    4. loudness and valence\n",
    "\n",
    "The other components - energy, danceability, valence, etc, already follow distributions.  Recall that our original goal is to come up with some model for determining what makes a song popular.  We can already surmise that songs that are instrumental in nature or follow a time signature other than 4/4 are not likely to be chart toppers.  After replacing key and mode with keyscore, 10 dimensions remain.  We reduce the dimensionality using PCA.  For this, we muse use the scikit-learn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "relevant = [\"danceability\", \"energy\", \"loudness\", \"valence\"]\n",
    "entries = sdata[\"artists\"] + \": \" + sdata[\"name\"]\n",
    "\n",
    "#must standardize\n",
    "x = sdata.loc[:, relevant].values\n",
    "x = StandardScaler().fit_transform(x)\n",
    "\n",
    "#pcatpca\n",
    "songpca = PCA(n_components=2)\n",
    "songpca.fit(x)\n",
    "components = songpca.transform(x)\n",
    "\n",
    "\n",
    "pca_df = pd.DataFrame(data = components)\n",
    "\n",
    "pca_df = pd.concat([pca_df, entries], axis = 1)\n",
    "pca_df.columns = ['pca1', 'pca2','songs']\n",
    "                        \n",
    "#visualize\n",
    "fig2_1 = plt.figure(figsize = (15,10))\n",
    "a = fig2_1.add_subplot(1,1,1) \n",
    "a.set_xlabel('Component 1', fontsize = 15)\n",
    "a.set_ylabel('Component 2', fontsize = 15)\n",
    "a.set_title('2-component PCA', fontsize = 20)\n",
    "\n",
    "a.scatter(pca_df['pca1'], pca_df['pca2'], c = 'blue', s = 50)\n",
    "\n",
    "\n",
    "a.grid()\n",
    "songpca.explained_variance_ratio_\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We will continue to give these data a closer look in order to build a model.  From this model we hope to put together some sort of argument that will tell us what combination of attributes creates a song with a lot of streams.\n",
    "\n",
    "Some ideas that we will apply here:\n",
    "+ Apply kde fit where appropriate (non-discretized values)\n",
    "+ From kde derive probabilistic models\n",
    "+ Deploy an initial neural network trained on this data set to find weights and see if our probabilitistic models work\n",
    "+ Add more data if possible, rinse and repeat to fine-tune"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
